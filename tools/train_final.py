#!/usr/bin/env python3
"""
Script d'entraÃ®nement pour CutLER sur dataset personnalisÃ©.
Utilise la configuration existante de CutLER.
"""

import sys
import argparse
import json
import subprocess
from pathlib import Path

def main():
    parser = argparse.ArgumentParser(description="EntraÃ®ner CutLER sur un dataset personnalisÃ©")
    parser.add_argument("--dataset-path", type=str, required=True,
                       help="Chemin vers le dataset personnalisÃ©")
    parser.add_argument("--output-dir", type=str, required=True,
                       help="RÃ©pertoire de sortie pour les rÃ©sultats")
    parser.add_argument("--num-classes", type=int, default=3,
                       help="Nombre de classes dans le dataset")
    parser.add_argument("--resume", action="store_true",
                       help="Reprendre l'entraÃ®nement depuis le dernier checkpoint")
    parser.add_argument("--eval-only", action="store_true",
                       help="Seulement Ã©valuer le modÃ¨le")
    parser.add_argument("--num-gpus", type=int, default=1,
                       help="Nombre de GPUs Ã  utiliser")
    
    args = parser.parse_args()
    
    print("Configuration de l'entraÃ®nement:")
    print(f"  Dataset: {args.dataset_path}")
    print(f"  Sortie: {args.output_dir}")
    print(f"  Classes: {args.num_classes}")
    print(f"  GPUs: {args.num_gpus}")
    
    # Valider les chemins
    dataset_path = Path(args.dataset_path)
    if not dataset_path.exists():
        print(f"âŒ Erreur: Dataset non trouvÃ©: {dataset_path}")
        return 1
    
    # VÃ©rifier la structure du dataset
    required_files = [
        dataset_path / "images" / "train",
        dataset_path / "images" / "val", 
        dataset_path / "annotations" / "instances_train.json",
        dataset_path / "annotations" / "instances_val.json"
    ]
    
    missing_files = []
    for file_path in required_files:
        if not file_path.exists():
            missing_files.append(str(file_path))
    
    if missing_files:
        print("âŒ Erreur: Fichiers/dossiers manquants:")
        for file in missing_files:
            print(f"  - {file}")
        return 1
    
    # Valider les annotations JSON
    try:
        train_annotations = dataset_path / "annotations" / "instances_train.json"
        val_annotations = dataset_path / "annotations" / "instances_val.json"
        
        with open(train_annotations) as f:
            train_data = json.load(f)
        with open(val_annotations) as f:
            val_data = json.load(f)
            
        print("âœ“ Annotations valides")
        print(f"  - Images d'entraÃ®nement: {len(train_data['images'])}")
        print(f"  - Annotations d'entraÃ®nement: {len(train_data['annotations'])}")
        print(f"  - Images de validation: {len(val_data['images'])}")
        print(f"  - Annotations de validation: {len(val_data['annotations'])}")
    except json.JSONDecodeError as e:
        print(f"âŒ Erreur dans les annotations JSON: {e}")
        return 1
    
    # CrÃ©er le rÃ©pertoire de sortie
    output_path = Path(args.output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Enregistrer le dataset avant l'entraÃ®nement
    print("ğŸ”§ Enregistrement du dataset...")
    try:
        # Ajouter le rÃ©pertoire parent au PYTHONPATH pour les imports
        sys.path.insert(0, str(Path(__file__).parent.parent))
        
        from cutler.data.datasets.custom_datasets import register_dataset_from_path
        
        dataset_name = dataset_path.name
        registered_datasets = register_dataset_from_path(dataset_name, str(dataset_path))
        print(f"âœ“ Dataset enregistrÃ©: {registered_datasets}")
        
    except ImportError as e:
        print(f"âŒ Erreur d'import pour l'enregistrement: {e}")
        print("Continuons sans prÃ©-enregistrement...")
    
    # Utiliser la configuration existante pour datasets personnalisÃ©s
    config_file = Path(__file__).parent.parent / "cutler" / "model_zoo" / "configs" / "Custom-Dataset" / "cascade_mask_rcnn_R_50_FPN_custom.yaml"
    
    if not config_file.exists():
        print(f"âŒ Configuration non trouvÃ©e: {config_file}")
        return 1
        
    print(f"ğŸ“ Configuration utilisÃ©e: {config_file}")
    
    # CrÃ©er les arguments pour train_net.py
    train_args = [
        sys.executable, "cutler/train_net.py",
        "--config-file", str(config_file),
        "--num-gpus", str(args.num_gpus),
        "DATASETS.TRAIN", f"('{dataset_path.name}_train',)",
        "DATASETS.TEST", f"('{dataset_path.name}_val',)",
        "OUTPUT_DIR", args.output_dir,
        "MODEL.ROI_HEADS.NUM_CLASSES", str(args.num_classes),
        "SOLVER.MAX_ITER", "300",  # Court pour test
        "SOLVER.STEPS", "(200, 250)",
        "SOLVER.CHECKPOINT_PERIOD", "100",
        "TEST.EVAL_PERIOD", "100"
    ]
    
    if args.resume:
        train_args.append("--resume")
    
    if args.eval_only:
        train_args.append("--eval-only")
    
    print("ğŸ“ Commande d'entraÃ®nement:")
    print(f"  {' '.join(train_args)}")
    
    print("ğŸ¯ DÃ©marrage de l'entraÃ®nement...")
    result = subprocess.run(train_args, cwd=str(Path(__file__).parent.parent))
    
    if result.returncode == 0:
        print("âœ… EntraÃ®nement terminÃ©!")
    else:
        print(f"âŒ Erreur pendant l'entraÃ®nement (code: {result.returncode})")
    
    return result.returncode

if __name__ == "__main__":
    sys.exit(main())
