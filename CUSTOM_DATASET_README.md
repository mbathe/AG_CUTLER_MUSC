# CutLER - Support pour Datasets PersonnalisÃ©s

Ce guide explique comment utiliser CutLER avec vos propres datasets pour l'entraÃ®nement de modÃ¨les de dÃ©tection d'objets non supervisÃ©s.

## ğŸš€ FonctionnalitÃ©s AjoutÃ©es

- **GÃ©nÃ©ration automatique de datasets synthÃ©tiques**
- **Support complet des datasets au format COCO**
- **Scripts d'entraÃ®nement adaptÃ©s pour datasets personnalisÃ©s**
- **Outils de visualisation et de comparaison**
- **Pipeline automatisÃ© de bout en bout**

## ğŸ“ Structure des Fichiers AjoutÃ©s

```
CutLER/
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ generate_custom_dataset.py    # GÃ©nÃ¨re un dataset synthÃ©tique
â”‚   â”œâ”€â”€ train_custom.py              # EntraÃ®ne sur dataset personnalisÃ©
â”‚   â”œâ”€â”€ visualize_custom.py          # Visualise les rÃ©sultats
â”‚   â””â”€â”€ run_custom_pipeline.py       # Script principal tout-en-un
â”œâ”€â”€ cutler/
â”‚   â”œâ”€â”€ data/datasets/
â”‚   â”‚   â””â”€â”€ custom_datasets.py       # Support datasets personnalisÃ©s
â”‚   â””â”€â”€ model_zoo/configs/Custom-Dataset/
â”‚       â””â”€â”€ cascade_mask_rcnn_R_50_FPN_custom.yaml
â””â”€â”€ test.ipynb                       # Notebook de dÃ©monstration
```

## ğŸ› ï¸ Installation et DÃ©pendances

### DÃ©pendances Python Requises

```bash
pip install numpy opencv-python matplotlib Pillow
```

### VÃ©rification de l'Installation

```python
python tools/run_custom_pipeline.py --help
```

## ğŸ“Š Utilisation Rapide

### 1. Test avec Dataset SynthÃ©tique

GÃ©nÃ©rez et testez rapidement avec un dataset d'exemple :

```bash
python tools/run_custom_pipeline.py \
    --workspace ./test_workspace \
    --num-train 100 \
    --num-val 20 \
    --num-classes 3
```

### 2. GÃ©nÃ©ration de Dataset SynthÃ©tique

```bash
python tools/generate_custom_dataset.py \
    --output-dir ./mon_dataset \
    --num-train 1000 \
    --num-val 200
```

Cela crÃ©e un dataset avec des formes gÃ©omÃ©triques (cercles, rectangles, triangles).

### 3. EntraÃ®nement sur Votre Dataset

```bash
python tools/train_custom.py \
    --dataset-path ./mon_dataset \
    --output-dir ./output \
    --num-classes 3
```

### 4. Visualisation des RÃ©sultats

```bash
# Annotations ground truth
python tools/visualize_custom.py \
    --dataset-path ./mon_dataset \
    --output-dir ./visualizations \
    --mode gt

# Comparaison GT vs PrÃ©dictions
python tools/visualize_custom.py \
    --dataset-path ./mon_dataset \
    --output-dir ./visualizations \
    --mode compare \
    --model-config ./output/config.yaml \
    --model-weights ./output/model_final.pth
```

## ğŸ“‹ Format du Dataset

### Structure Requise

```
mon_dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ image001.jpg
â”‚   â”‚   â”œâ”€â”€ image002.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â”œâ”€â”€ image001.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ test/ (optionnel)
â”‚       â””â”€â”€ ...
â””â”€â”€ annotations/
    â”œâ”€â”€ instances_train.json
    â”œâ”€â”€ instances_val.json
    â””â”€â”€ instances_test.json (optionnel)
```

### Format des Annotations (COCO JSON)

```json
{
  "info": {
    "description": "Mon Dataset PersonnalisÃ©",
    "version": "1.0",
    "year": 2024
  },
  "categories": [
    {"id": 1, "name": "classe1", "supercategory": "objet"},
    {"id": 2, "name": "classe2", "supercategory": "objet"}
  ],
  "images": [
    {
      "id": 1,
      "width": 640,
      "height": 480,
      "file_name": "image001.jpg"
    }
  ],
  "annotations": [
    {
      "id": 1,
      "image_id": 1,
      "category_id": 1,
      "segmentation": [[x1, y1, x2, y2, ...]],
      "area": 12345,
      "bbox": [x, y, width, height],
      "iscrowd": 0
    }
  ]
}
```

## âš™ï¸ Configuration AvancÃ©e

### ParamÃ¨tres d'EntraÃ®nement

Modifiez `cutler/model_zoo/configs/Custom-Dataset/cascade_mask_rcnn_R_50_FPN_custom.yaml` :

```yaml
MODEL:
  ROI_HEADS:
    NUM_CLASSES: 10  # Votre nombre de classes

SOLVER:
  IMS_PER_BATCH: 4     # Taille du batch
  BASE_LR: 0.002       # Taux d'apprentissage
  MAX_ITER: 5000       # Nombre d'itÃ©rations
  STEPS: (3000, 4000)  # Ã‰tapes de rÃ©duction du LR

DATALOADER:
  NUM_WORKERS: 4       # Nombre de workers
```

### Classes PersonnalisÃ©es

Dans `cutler/data/datasets/custom_datasets.py`, modifiez :

```python
CUSTOM_CATEGORIES = [
    {"id": 1, "name": "ma_classe1", "supercategory": "objet"},
    {"id": 2, "name": "ma_classe2", "supercategory": "objet"},
    # Ajoutez vos classes...
]
```

## ğŸ“ˆ Monitoring et Ã‰valuation

### TensorBoard

```bash
tensorboard --logdir ./output
```

### MÃ©triques d'Ã‰valuation

Le systÃ¨me utilise les mÃ©triques COCO standard :
- **AP (Average Precision)** Ã  diffÃ©rents seuils IoU
- **AR (Average Recall)** 
- **AP par classe**

### Logs d'EntraÃ®nement

Consultez `./output/log.txt` pour suivre la progression.

## ğŸ”§ DÃ©pannage

### ProblÃ¨mes Courants

1. **Erreur de mÃ©moire GPU**
   ```yaml
   SOLVER:
     IMS_PER_BATCH: 1  # RÃ©duire la taille du batch
   ```

2. **Dataset non trouvÃ©**
   - VÃ©rifiez la structure des dossiers
   - VÃ©rifiez les chemins dans les fichiers JSON

3. **Erreur de format JSON**
   - Validez votre JSON avec un validateur en ligne
   - VÃ©rifiez que tous les IDs sont uniques

### Validation du Dataset

```python
python tools/visualize_custom.py \
    --dataset-path ./mon_dataset \
    --output-dir ./validation \
    --mode gt \
    --num-images 10
```

## ğŸ¯ Examples d'Utilisation

### Dataset d'Images MÃ©dicales

```bash
python tools/train_custom.py \
    --dataset-path ./medical_images \
    --output-dir ./medical_model \
    --num-classes 5
```

### Dataset de VÃ©hicules

```bash
python tools/train_custom.py \
    --dataset-path ./vehicles_dataset \
    --output-dir ./vehicle_detector \
    --num-classes 8
```

### Dataset de Produits

```bash
python tools/train_custom.py \
    --dataset-path ./products_dataset \
    --output-dir ./product_detector \
    --num-classes 20
```

## ğŸ“š Ressources SupplÃ©mentaires

- [Documentation COCO Format](https://cocodataset.org/#format-data)
- [Documentation Detectron2](https://detectron2.readthedocs.io/)
- [Paper CutLER Original](https://arxiv.org/abs/2301.11320)

## ğŸ¤ Contribution

Pour contribuer Ã  l'amÃ©lioration du support des datasets personnalisÃ©s :

1. CrÃ©ez une issue pour discuter des changements
2. Fork le repository
3. CrÃ©ez votre feature branch
4. Testez vos modifications
5. Soumettez une pull request

## ğŸ“„ License

Ce code suit la mÃªme licence que le projet CutLER original.

---

**Note** : Ce systÃ¨me est conÃ§u pour Ãªtre facile Ã  utiliser tout en conservant la flexibilitÃ© nÃ©cessaire pour des cas d'usage avancÃ©s. N'hÃ©sitez pas Ã  adapter les configurations selon vos besoins spÃ©cifiques.
